{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "afe1e266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import NearestNeighborModels ✔\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: For silent loading, specify `verbosity=0`. \n",
      "└ @ Main C:\\Users\\Usuario\\.julia\\packages\\MLJModels\\ziReN\\src\\loading.jl:159\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1-element Vector{Symbol}:\n",
       " :cross_val_index"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using JLD2\n",
    "using Flux\n",
    "using MLJ\n",
    "using MLJLIBSVMInterface\n",
    "using StatisticalMeasures\n",
    "using CategoricalArrays\n",
    "MLJ.@load KNNClassifier pkg=NearestNeighborModels\n",
    "\n",
    "include(\"../src/filters.jl\")\n",
    "include(\"../src/reduction.jl\")\n",
    "\n",
    "@JLD2.load \"variables/train_dataset.jld2\" train_inputs train_targets\n",
    "@JLD2.load \"variables/test_dataset.jld2\" test_inputs test_targets\n",
    "@JLD2.load \"variables/cross_val_index.jdl2\" cross_val_index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ea4b92",
   "metadata": {},
   "source": [
    "### Constructor de arquitectura MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "b471b018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "buildANN (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function buildANN(n_inputs::Int, hidden_layers::Vector{Int}, n_outputs::Int; activation = relu)\n",
    "    layers = Any[]\n",
    "\n",
    "    # capas ocultas\n",
    "    in_dim = n_inputs\n",
    "    for h in hidden_layers\n",
    "        push!(layers, Dense(in_dim, h, activation))\n",
    "        in_dim = h\n",
    "    end\n",
    "\n",
    "    # capa de salida\n",
    "    push!(layers, Dense(in_dim, n_outputs))\n",
    "    push!(layers, Flux.softmax)\n",
    "\n",
    "    return Chain(layers...)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde94a84",
   "metadata": {},
   "source": [
    "### Entrenamiento de dicho MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "8d0a1b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "function trainANN(ann::Chain, dataset::Tuple{DataFrame, BitArray};\n",
    "    epochs::Int=1000, learningRate::Real=0.001, minLossChange::Real=1e-7, lossChangeWindowSize::Int=5)\n",
    "\n",
    "    inputs = Matrix(dataset[1]) |> x -> Float32.(x)\n",
    "    targets = Matrix(dataset[2]) |> x -> Float32.(x)\n",
    "    # Flux espera columnas = muestras\n",
    "    inputs = inputs'\n",
    "    targets = targets'\n",
    "\n",
    "    loss(model, x, y) = Flux.Losses.crossentropy(model(x), y);\n",
    "    trainingLosses = Float32[loss(ann, inputs, targets)];\n",
    "    opt_state = Flux.setup(Adam(learningRate), ann);\n",
    "\n",
    "    for epoch in 1:epochs\n",
    "        Flux.train!(loss, ann, [(inputs, targets)], opt_state);\n",
    "        current_loss = Float32(loss(ann, inputs, targets));\n",
    "        push!(trainingLosses, current_loss);\n",
    "    end;\n",
    "\n",
    "    # Predicciones\n",
    "    ŷ = ann(inputs) \n",
    "    y_pred = Flux.onecold(ŷ)           # Covertimos a One-hot-encoding\n",
    "    y_true = Flux.onecold(targets)\n",
    "\n",
    "    # A formato MLJ\n",
    "    y_pred_cat = categorical(y_pred)\n",
    "    y_true_cat = categorical(y_true)\n",
    "\n",
    "    cm = confusion_matrix(y_true_cat, y_pred_cat)\n",
    "\n",
    "    # Sensitivity (recall) de la clase 1\n",
    "    sens = MLJ.sensitivity(cm)\n",
    "\n",
    "    # Accuracy\n",
    "    acc = MLJ.accuracy(cm)\n",
    "\n",
    "    return (\n",
    "        losses = trainingLosses,\n",
    "        accuracy = acc,\n",
    "        sensitivity = sens\n",
    "    )\n",
    "\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfab6c9c",
   "metadata": {},
   "source": [
    "### Creación y entrenamiento de SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a03703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "createSVM (generic function with 2 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function createSVM(dataset::Tuple{DataFrame, BitArray}, kernel::String, C::Real; gamma::Real=1.0, degree::Int=3, coef0::Real=0.0)\n",
    "\n",
    "    # deshacemos One-Hot-Encoding \n",
    "    inputs, labels = dataset; \n",
    "    targets = [sum(findall(row)) for row in eachrow(labels)]\n",
    "\n",
    "    if kernel == \"linear\"\n",
    "        k = LIBSVM.Kernel.Linear\n",
    "    elseif kernel == \"rbf\"\n",
    "        k = LIBSVM.Kernel.RadialBasis\n",
    "    elseif kernel == \"poly\"\n",
    "        k = LIBSVM.Kernel.Polynomial\n",
    "    elseif kernel == \"sigmoid\"\n",
    "        k = LIBSVM.Kernel.Sigmoid\n",
    "    else\n",
    "        error(\"Kernel no soportado: $kernel\")\n",
    "    end\n",
    "\n",
    "    model = SVMClassifier(\n",
    "        kernel = k,\n",
    "        cost = Float64(C),\n",
    "        gamma = Float64(gamma),\n",
    "        degree = Int32(degree),\n",
    "        coef0 = Float64(coef0)\n",
    "    )\n",
    "\n",
    "    mach = machine(\n",
    "        model,\n",
    "        inputs,\n",
    "        categorical(targets)\n",
    "    )\n",
    "\n",
    "    MLJ.fit!(mach)\n",
    "\n",
    "    # Predicciones sobre el mismo conjunto\n",
    "    y_pred = MLJ.predict(mach, inputs)\n",
    "    y_pred_labels = mode.(y_pred)           # Extrae los labels\n",
    "    y_pred_vec = Int.(y_pred_labels)     # Vector{Int}\n",
    "    y_pred_cat = categorical(y_pred_vec)    # Vector categórico\n",
    "\n",
    "    y_true_cat = categorical(targets)\n",
    "\n",
    "    # Métricas\n",
    "    cm = confusion_matrix(y_true_cat, y_pred_cat)\n",
    "    acc = accuracy(cm)\n",
    "    sens = sensitivity(cm)\n",
    "\n",
    "\n",
    "    cm = confusion_matrix(y_true_cat, y_pred_cat)\n",
    "    acc = accuracy(cm)\n",
    "    sens = sensitivity(cm)\n",
    "    \n",
    "    return mach, acc, sens\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386e494a",
   "metadata": {},
   "source": [
    "#### Creación y entrenamiento de KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb91724c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "createKNN (generic function with 4 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function createKNN(dataset::Tuple{DataFrame, AbstractMatrix}; k::Int = 5)\n",
    "\n",
    "    # Deshacemos One-Hot-Encoding   \n",
    "    inputs, labels = dataset; \n",
    "    targets = [sum(findall(row)) for row in eachrow(labels)]\n",
    "\n",
    "    model = NearestNeighborModels.KNNClassifier(K = k)\n",
    "\n",
    "    mach = machine(\n",
    "        model,\n",
    "        inputs,\n",
    "        categorical(targets)\n",
    "    )\n",
    "\n",
    "    MLJ.fit!(mach)\n",
    "    # Predicciones sobre el mismo conjunto\n",
    "    y_pred = MLJ.predict(mach, inputs)\n",
    "    y_pred_labels = mode.(y_pred)           # Extrae los labels\n",
    "    y_pred_vec = Int.(y_pred_labels)     # Vector{Int}\n",
    "    y_pred_cat = categorical(y_pred_vec)    # Vector categórico\n",
    "\n",
    "    y_true_cat = categorical(targets)\n",
    "\n",
    "    # Métricas\n",
    "    cm = confusion_matrix(y_true_cat, y_pred_cat)\n",
    "    acc = accuracy(cm)\n",
    "    sens = sensitivity(cm)\n",
    "\n",
    "\n",
    "    cm = confusion_matrix(y_true_cat, y_pred_cat)\n",
    "    acc = accuracy(cm)\n",
    "    sens = sensitivity(cm)\n",
    "    \n",
    "    return mach, acc, sens\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fc5141",
   "metadata": {},
   "source": [
    "## Entrenamiento de clasificadores con filtrado y reducción (sin Cross Validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a767f811",
   "metadata": {},
   "source": [
    "##### PCA + ANOVA + ANN ([50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "28d6f324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7785830178474852\n",
      "0.748650732459522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: Levels not explicitly ordered. Using the order CategoricalValue{Int64, UInt32}[1, 2, 3, 4, 5, 6]. \n",
      "└ @ StatisticalMeasures.ConfusionMatrices C:\\Users\\Usuario\\.julia\\packages\\StatisticalMeasures\\UTtxb\\src\\confusion_matrices.jl:339\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = train_inputs, train_targets\n",
    "\n",
    "# 1. PCA\n",
    "X_pca, pca_model = pca(inputs, 0.95)\n",
    "\n",
    "# 2. ANOVA\n",
    "anova_scores = anova((X_pca, train_targets));\n",
    "anova_index = findall(x -> x >= 0.3, anova_scores);\n",
    "new_dataset = (X_pca[:, anova_index], train_targets);\n",
    "\n",
    "# 3. ANN\n",
    "n_inputs = size(new_dataset[1], 2)\n",
    "n_outputs = size(new_dataset[2], 2)\n",
    "ann_model = buildANN(n_inputs, [50], n_outputs)\n",
    "losses, accuracy, sensitivity = trainANN(ann_model, (new_dataset[1], new_dataset[2]))\n",
    "\n",
    "println(accuracy)\n",
    "println(sensitivity)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebbc2ed",
   "metadata": {},
   "source": [
    "##### PEARSON + LDA + SVM (c=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "66629bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training machine(SVC(kernel = Linear, …), …).\n",
      "└ @ MLJBase C:\\Users\\Usuario\\.julia\\packages\\MLJBase\\7nGJF\\src\\machines.jl:499\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "trained Machine; caches model-specific representations of data\n",
       "  model: SVC(kernel = Linear, …)\n",
       "  args: \n",
       "    1:\tSource @812 ⏎ Table{AbstractVector{Continuous}}\n",
       "    2:\tSource @258 ⏎ AbstractVector{Multiclass{6}}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. PEARSON\n",
    "filtered_train_inputs, correlations = pearson((train_inputs, train_targets))\n",
    "new_dataset = (filtered_train_inputs, train_targets);\n",
    "\n",
    "# 2. LDA\n",
    "X_proj, W = lda(new_dataset)\n",
    "X_proj_real = real.(X_proj)      # si hay complejos, toma la parte real\n",
    "X_proj_clean = coalesce.(X_proj_real, 0.0)   # rellena posibles missing con 0\n",
    "X_lda = DataFrame(X_proj_clean, :auto)\n",
    "new_dataset = (X_lda, train_targets)\n",
    "\n",
    "# 3. SVM\n",
    "mach = createSVM(new_dataset, \"linear\", 0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a07e38",
   "metadata": {},
   "source": [
    "##### RFE + (sin reducción de dimensionalidad) + KNN(k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "6e7d7335",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training machine(KNNClassifier(K = 20, …), …).\n",
      "└ @ MLJBase C:\\Users\\Usuario\\.julia\\packages\\MLJBase\\7nGJF\\src\\machines.jl:499\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "trained Machine; caches model-specific representations of data\n",
       "  model: KNNClassifier(K = 20, …)\n",
       "  args: \n",
       "    1:\tSource @993 ⏎ Table{AbstractVector{Continuous}}\n",
       "    2:\tSource @876 ⏎ AbstractVector{Multiclass{6}}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. RFE \n",
    "filtered_features = rfe_logistic((train_inputs, train_targets));\n",
    "filtered_features_names = names(train_inputs)[filtered_features]\n",
    "\n",
    "# eliminamos valores faltantes\n",
    "X_clean = DataFrame(\n",
    "    coalesce.(Matrix(train_inputs[:, filtered_features_names]), 0.0),\n",
    "    names(train_inputs[:, filtered_features_names])\n",
    ")\n",
    "\n",
    "new_dataset = (X_clean, train_targets);\n",
    "\n",
    "# Sin reducción de dimensionalidad\n",
    "\n",
    "# 2. KNN\n",
    "mach = createKNN(new_dataset; k=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3c189d",
   "metadata": {},
   "source": [
    "##### KENDALL + ICA + KNN(k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49abc6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training machine(KNNClassifier(K = 10, …), …).\n",
      "└ @ MLJBase C:\\Users\\Usuario\\.julia\\packages\\MLJBase\\7nGJF\\src\\machines.jl:499\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "trained Machine; caches model-specific representations of data\n",
       "  model: KNNClassifier(K = 10, …)\n",
       "  args: \n",
       "    1:\tSource @912 ⏎ Table{AbstractVector{Continuous}}\n",
       "    2:\tSource @325 ⏎ AbstractVector{Multiclass{6}}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. KENDALL\n",
    "kendall_coeff = kendall((train_inputs, train_targets))\n",
    "kendall_index = findall(x -> x >= 0.3, kendall_coeff);\n",
    "new_dataset = (train_inputs[:, kendall_index], train_targets);\n",
    "\n",
    "# 2. ICA\n",
    "S, W = fastica(new_dataset; tol=0.01, max_iter=100)\n",
    "S = DataFrame(S, :auto)\n",
    "new_dataset = (S, train_targets)\n",
    "\n",
    "# 3. KNN\n",
    "mach = createKNN(new_dataset; k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91a3be1",
   "metadata": {},
   "source": [
    "##### SPEARMAN + LDA + ANN([100, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "303d9398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1001-element Vector{Float32}:\n",
       " 1.7307363\n",
       " 1.7010912\n",
       " 1.6721834\n",
       " 1.6442572\n",
       " 1.6174283\n",
       " 1.5916183\n",
       " 1.5664014\n",
       " 1.5416322\n",
       " 1.5173337\n",
       " 1.4934605\n",
       " ⋮\n",
       " 0.23180948\n",
       " 0.23177567\n",
       " 0.23173955\n",
       " 0.23171045\n",
       " 0.23167728\n",
       " 0.23164198\n",
       " 0.23160861\n",
       " 0.23157687\n",
       " 0.23154181"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. SPEARMAN\n",
    "spearman_scores = spearman((train_inputs, train_targets));\n",
    "spearman_index = findall(x -> x >= 0.01, spearman_scores);\n",
    "new_dataset = (train_inputs[:, spearman_index], train_targets);\n",
    "\n",
    "# 2. LDA\n",
    "X_proj, W = lda(new_dataset)\n",
    "X_proj_real = real.(X_proj)      # si hay complejos, toma la parte real\n",
    "X_proj_clean = coalesce.(X_proj_real, 0.0)   # rellena posibles missing con 0\n",
    "X_lda = DataFrame(X_proj_clean, :auto)\n",
    "new_dataset = (X_lda, train_targets)\n",
    "\n",
    "# 3. ANN\n",
    "n_inputs = size(new_dataset[1], 2)\n",
    "n_outputs = size(new_dataset[2], 2)\n",
    "ann_model = buildANN(n_inputs, [100,50], n_outputs)\n",
    "losses = trainANN(ann_model, (new_dataset[1], new_dataset[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ea7010",
   "metadata": {},
   "source": [
    "##### (sin filtrado) + PCA + SVM(c=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953d8743",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training machine(SVC(kernel = Linear, …), …).\n",
      "└ @ MLJBase C:\\Users\\Usuario\\.julia\\packages\\MLJBase\\7nGJF\\src\\machines.jl:499\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "trained Machine; caches model-specific representations of data\n",
       "  model: SVC(kernel = Linear, …)\n",
       "  args: \n",
       "    1:\tSource @108 ⏎ Table{AbstractVector{Continuous}}\n",
       "    2:\tSource @888 ⏎ AbstractVector{Multiclass{6}}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. PCA\n",
    "X_pca, pca_model = pca(inputs, 0.95)\n",
    "\n",
    "# 2. SVM\n",
    "mach = createSVM(new_dataset, \"linear\", 1.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b9bef2",
   "metadata": {},
   "source": [
    "##### PEARSON + LDA + ANN([100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "39b1aee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1001-element Vector{Float32}:\n",
       " 1.7635249\n",
       " 1.7449391\n",
       " 1.7266634\n",
       " 1.7086916\n",
       " 1.6910176\n",
       " 1.6736385\n",
       " 1.6565499\n",
       " 1.6397454\n",
       " 1.6232218\n",
       " 1.6069708\n",
       " ⋮\n",
       " 0.313009\n",
       " 0.3129705\n",
       " 0.31293198\n",
       " 0.31289357\n",
       " 0.31285518\n",
       " 0.31281686\n",
       " 0.3127786\n",
       " 0.3127404\n",
       " 0.31270224"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. PEARSON \n",
    "filtered_train_inputs, correlations = pearson((train_inputs, train_targets), threshold=0.1);\n",
    "new_dataset = (filtered_train_inputs, train_targets);\n",
    "\n",
    "# 2. LDA\n",
    "X_proj, W = lda(new_dataset)\n",
    "X_proj_real = real.(X_proj)      # si hay complejos, toma la parte real\n",
    "X_proj_clean = coalesce.(X_proj_real, 0.0)   # rellena posibles missing con 0\n",
    "X_lda = DataFrame(X_proj_clean, :auto)\n",
    "new_dataset = (X_lda, train_targets)\n",
    "\n",
    "# 3. ANN\n",
    "n_inputs = size(new_dataset[1], 2)\n",
    "n_outputs = size(new_dataset[2], 2)\n",
    "ann_model = buildANN(n_inputs, [100], n_outputs)\n",
    "losses = trainANN(ann_model, (new_dataset[1], new_dataset[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274dbae8",
   "metadata": {},
   "source": [
    "##### KENDALL + (sin reducción) + SVM(c=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f5158559",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training machine(SVC(kernel = Linear, …), …).\n",
      "└ @ MLJBase C:\\Users\\Usuario\\.julia\\packages\\MLJBase\\7nGJF\\src\\machines.jl:499\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "trained Machine; caches model-specific representations of data\n",
       "  model: SVC(kernel = Linear, …)\n",
       "  args: \n",
       "    1:\tSource @160 ⏎ Table{AbstractVector{Continuous}}\n",
       "    2:\tSource @715 ⏎ AbstractVector{Multiclass{6}}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. KENDALL\n",
    "kendall_coeff = kendall((train_inputs, train_targets))\n",
    "kendall_index = findall(x -> x >= 0.3, kendall_coeff);\n",
    "\n",
    "# Eliminamos datos missing\n",
    "X_clean = DataFrame(\n",
    "    coalesce.(Matrix(train_inputs[:, kendall_index]), 0.0),\n",
    "    names(train_inputs[:, kendall_index])\n",
    ")\n",
    "\n",
    "new_dataset = (X_clean, train_targets);\n",
    "\n",
    "# 2. SVM\n",
    "mach = createSVM(new_dataset, \"linear\", 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f599979",
   "metadata": {},
   "source": [
    "#### (sin filtrado) + LDA + KNN(k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8d71a525",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training machine(KNNClassifier(K = 1, …), …).\n",
      "└ @ MLJBase C:\\Users\\Usuario\\.julia\\packages\\MLJBase\\7nGJF\\src\\machines.jl:499\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "trained Machine; caches model-specific representations of data\n",
       "  model: KNNClassifier(K = 1, …)\n",
       "  args: \n",
       "    1:\tSource @291 ⏎ Table{AbstractVector{Continuous}}\n",
       "    2:\tSource @785 ⏎ AbstractVector{Multiclass{6}}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. LDA\n",
    "X_proj, W = lda(new_dataset)\n",
    "X_proj_real = real.(X_proj)      # si hay complejos, toma la parte real\n",
    "X_proj_clean = coalesce.(X_proj_real, 0.0)   # rellena posibles missing con 0\n",
    "X_lda = DataFrame(X_proj_clean, :auto)\n",
    "new_dataset = (X_lda, train_targets)\n",
    "\n",
    "# 2. KNN\n",
    "mach = createKNN(new_dataset; k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed76938c",
   "metadata": {},
   "source": [
    "## Entrenamiento de clasificadores con filtrado y reducción (ahora con Cross Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da19e6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1"
     ]
    },
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching trainANN(::Chain{Tuple{Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, typeof(softmax)}}, ::Tuple{DataFrame, BitMatrix}, ::Tuple{DataFrame, BitMatrix})\nThe function `trainANN` exists, but no method is defined for this combination of argument types.\n\nClosest candidates are:\n  trainANN(::Chain, ::Tuple{DataFrame, BitArray}; epochs, learningRate, minLossChange, lossChangeWindowSize)\n   @ Main c:\\Users\\Usuario\\Documents\\adrispul\\Universidad\\INTELIGENCIA ARTIFICIAL\\3º\\1º SEMESTRE\\MAAA\\PRÁCTICAS\\GitHub_Repository\\Practicas_Julia\\Practica4\\notebooks\\jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W2sZmlsZQ==.jl:1\n",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching trainANN(::Chain{Tuple{Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, typeof(softmax)}}, ::Tuple{DataFrame, BitMatrix}, ::Tuple{DataFrame, BitMatrix})\n",
      "The function `trainANN` exists, but no method is defined for this combination of argument types.\n",
      "\n",
      "Closest candidates are:\n",
      "  trainANN(::Chain, ::Tuple{DataFrame, BitArray}; epochs, learningRate, minLossChange, lossChangeWindowSize)\n",
      "   @ Main c:\\Users\\Usuario\\Documents\\adrispul\\Universidad\\INTELIGENCIA ARTIFICIAL\\3º\\1º SEMESTRE\\MAAA\\PRÁCTICAS\\GitHub_Repository\\Practicas_Julia\\Practica4\\notebooks\\jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W2sZmlsZQ==.jl:1\n",
      "\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ c:\\Users\\Usuario\\Documents\\adrispul\\Universidad\\INTELIGENCIA ARTIFICIAL\\3º\\1º SEMESTRE\\MAAA\\PRÁCTICAS\\GitHub_Repository\\Practicas_Julia\\Practica4\\notebooks\\jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X53sZmlsZQ==.jl:34"
     ]
    }
   ],
   "source": [
    "k = maximum(cross_val_index)\n",
    "accuracies = Float64[]\n",
    "sensitivities = Float64[]\n",
    "\n",
    "for fold in 1:k\n",
    "    println(\"Fold $fold\")\n",
    "\n",
    "    train_idx = findall(x -> x != fold, cross_val_index)\n",
    "    test_idx  = findall(x -> x == fold, cross_val_index)\n",
    "\n",
    "    X_train = inputs[train_idx, :]\n",
    "    y_train = targets[train_idx, :]\n",
    "\n",
    "    X_test  = inputs[test_idx, :]\n",
    "    y_test  = targets[test_idx, :]\n",
    "\n",
    "    # 2. PCA (solo con train)\n",
    "    X_train_pca, pca_model = pca(X_train, 0.95)\n",
    "    X_test_pca = pca(X_test, 0.95)\n",
    "\n",
    "    # 3. ANOVA (solo con train)\n",
    "    anova_scores = anova((X_train_pca, y_train))\n",
    "    selected_idx = findall(x -> x >= 0.3, anova_scores)\n",
    "\n",
    "    X_train_sel = X_train_pca[:, selected_idx]\n",
    "    X_test_sel  = X_test_pca[:, selected_idx]\n",
    "\n",
    "    # 4. ANN\n",
    "    n_inputs = size(X_train_sel, 2)\n",
    "    n_outputs = size(y_train, 2)\n",
    "\n",
    "    ann_model = buildANN(n_inputs, [50], n_outputs)\n",
    "\n",
    "    losses, acc, sens = trainANN(ann_model, (X_train_sel, y_train), \n",
    "                                 (X_test_sel, y_test))\n",
    "\n",
    "    push!(accuracies, acc)\n",
    "    push!(sensitivities, sens)\n",
    "\n",
    "    println(\"Fold $fold → accuracy = $acc, sensitivity = $sens\")\n",
    "end\n",
    "\n",
    "println(\"\\n=== RESULTADOS FINALES ===\")\n",
    "println(\"Accuracy promedio: \", mean(accuracies))\n",
    "println(\"Sensitivity promedio: \", mean(sensitivities))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa31fed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.7",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
